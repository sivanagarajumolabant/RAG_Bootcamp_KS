{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìÅ Notebook 02: Document Loaders\n",
    "\n",
    "**LangChain 1.0.5+ | Mixed Level Class**\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Load documents from **PDF files** using PyPDFLoader\n",
    "2. Load structured data from **CSV files**\n",
    "3. Load JSON data from **API responses** or files\n",
    "4. Scrape and load content from **web pages** (HTML)\n",
    "5. Load **text files** and **markdown files**\n",
    "6. **Batch process** multiple files using DirectoryLoader\n",
    "7. Understand Document object structure\n",
    "\n",
    "---\n",
    "\n",
    "## üìñ Table of Contents\n",
    "\n",
    "1. [Why Document Loaders?](#why-loaders)\n",
    "2. [Document Object Structure](#document-structure)\n",
    "3. [Loading PDF Files](#pdf-loading)\n",
    "4. [Loading CSV Files](#csv-loading)\n",
    "5. [Loading JSON Files](#json-loading)\n",
    "6. [Loading Web Pages (HTML)](#html-loading)\n",
    "7. [Loading Text and Markdown Files](#text-loading)\n",
    "8. [Batch Loading with DirectoryLoader](#batch-loading)\n",
    "9. [Comparison Table](#comparison)\n",
    "10. [Best Practices](#best-practices)\n",
    "11. [Summary & Exercises](#summary)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"why-loaders\"></a>\n",
    "## 1. Why Document Loaders? ü§î\n",
    "\n",
    "### üî∞ BEGINNER\n",
    "\n",
    "**Document Loaders** are tools that help you convert files (PDFs, CSVs, web pages, etc.) into **Document objects** that LangChain can work with.\n",
    "\n",
    "Think of them as **translators**:\n",
    "- **Input**: Files in various formats (PDF, CSV, JSON, HTML)\n",
    "- **Output**: Standardized Document objects with text content and metadata\n",
    "\n",
    "### Why is this important?\n",
    "\n",
    "Every RAG application needs to:\n",
    "1. üì• **Load** data from various sources\n",
    "2. üîÑ **Convert** it to a standard format\n",
    "3. üìä **Extract** metadata (source, page number, etc.)\n",
    "4. üéØ **Prepare** it for embedding and retrieval\n",
    "\n",
    "Document Loaders handle all of this automatically!\n",
    "\n",
    "### üéì INTERMEDIATE\n",
    "\n",
    "All document loaders in LangChain implement the same interface:\n",
    "- `.load()`: Load all documents at once (returns list[Document])\n",
    "- `.lazy_load()`: Load documents one at a time (generator, memory efficient)\n",
    "\n",
    "This consistency makes it easy to switch between different data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment loaded\n",
      "Current directory: /Users/sourangshupal/Downloads/simple-rag-langchain\n",
      "Sample data directory exists: True\n"
     ]
    }
   ],
   "source": [
    "# Setup: Import required libraries\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Verify setup\n",
    "print(\"‚úÖ Environment loaded\")\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "print(f\"Sample data directory exists: {Path('sample_data').exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"document-structure\"></a>\n",
    "## 2. Document Object Structure üìÑ\n",
    "\n",
    "### üî∞ BEGINNER\n",
    "\n",
    "Every Document has two main parts:\n",
    "1. **page_content**: The actual text (string)\n",
    "2. **metadata**: Information about the document (dictionary)\n",
    "\n",
    "Think of it like a book:\n",
    "- **page_content** = The story\n",
    "- **metadata** = The cover information (title, author, page number, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Document Structure:\n",
      "\n",
      "Type: <class 'langchain_core.documents.base.Document'>\n",
      "\n",
      "Content (first 100 chars): This is the actual content of the document. It contains the text we want to process....\n",
      "\n",
      "Metadata: {'source': 'example.pdf', 'page': 1, 'author': 'John Doe', 'date': '2025-01-15'}\n",
      "\n",
      "Source: example.pdf\n",
      "Page Number: 1\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "# Create a sample document\n",
    "doc = Document(\n",
    "    page_content=\"This is the actual content of the document. It contains the text we want to process.\",\n",
    "    metadata={\n",
    "        \"source\": \"example.pdf\",\n",
    "        \"page\": 1,\n",
    "        \"author\": \"John Doe\",\n",
    "        \"date\": \"2025-01-15\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Inspect the document\n",
    "print(\"üìÑ Document Structure:\")\n",
    "print(f\"\\nType: {type(doc)}\")\n",
    "print(f\"\\nContent (first 100 chars): {doc.page_content[:100]}...\")\n",
    "print(f\"\\nMetadata: {doc.metadata}\")\n",
    "print(f\"\\nSource: {doc.metadata['source']}\")\n",
    "print(f\"Page Number: {doc.metadata['page']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pdf-loading\"></a>\n",
    "## 3. Loading PDF Files üìï\n",
    "\n",
    "### üî∞ BEGINNER\n",
    "\n",
    "**PyPDFLoader** is used to load PDF files. It:\n",
    "- Extracts text from each page\n",
    "- Creates one Document per page\n",
    "- Automatically adds source and page number to metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Loading a Single PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PDF: attention.pdf\n",
      "‚è≥ This may take a moment...\n",
      "\n",
      "‚úÖ Loaded 15 pages\n",
      "\n",
      "üìÑ First Page:\n",
      "   Content (first 200 chars): Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and figures in this paper solely for use in journalistic or\n",
      "scholarly works.\n",
      "Attention Is All You Need\n",
      "...\n",
      "\n",
      "   Metadata: {'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'attention.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}\n",
      "\n",
      "üìÑ Last Page (page 15):\n",
      "   Content (first 200 chars): Input-Input Layer5\n",
      "The\n",
      "Law\n",
      "will\n",
      "never\n",
      "be\n",
      "perfect\n",
      ",\n",
      "but\n",
      "its\n",
      "application\n",
      "should\n",
      "be\n",
      "just\n",
      "-\n",
      "this\n",
      "is\n",
      "what\n",
      "we\n",
      "are\n",
      "missing\n",
      ",\n",
      "in\n",
      "my\n",
      "opinion\n",
      ".\n",
      "<EOS>\n",
      "<pad>\n",
      "The\n",
      "Law\n",
      "will\n",
      "never\n",
      "be\n",
      "perfect\n",
      ",\n",
      "but\n",
      "its\n",
      "application\n",
      "sh...\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load the \"Attention is All You Need\" paper (if it exists)\n",
    "pdf_path = \"attention.pdf\"\n",
    "\n",
    "if Path(pdf_path).exists():\n",
    "    print(f\"Loading PDF: {pdf_path}\")\n",
    "    print(\"‚è≥ This may take a moment...\\n\")\n",
    "    \n",
    "    # Create loader\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    \n",
    "    # Load all pages\n",
    "    documents = loader.load()\n",
    "    \n",
    "    print(f\"‚úÖ Loaded {len(documents)} pages\\n\")\n",
    "    \n",
    "    # Inspect first page\n",
    "    print(\"üìÑ First Page:\")\n",
    "    print(f\"   Content (first 200 chars): {documents[0].page_content[:200]}...\")\n",
    "    print(f\"\\n   Metadata: {documents[0].metadata}\")\n",
    "    \n",
    "    # Inspect last page\n",
    "    print(f\"\\nüìÑ Last Page (page {len(documents)}):\")\n",
    "    print(f\"   Content (first 200 chars): {documents[-1].page_content[:200]}...\")\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ùå PDF not found: {pdf_path}\")\n",
    "    print(\"   Make sure the file exists in the project root\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéì INTERMEDIATE: Lazy Loading for Large PDFs\n",
    "\n",
    "For very large PDFs, use `.lazy_load()` to process one page at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Lazy loading pages (memory efficient):\n",
      "\n",
      "Page 1:\n",
      "  Length: 2859 characters\n",
      "  Preview: Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and...\n",
      "\n",
      "Page 2:\n",
      "  Length: 4257 characters\n",
      "  Preview: 1 Introduction\n",
      "Recurrent neural networks, long short-term memory [13] and gated recurrent [7] neural...\n",
      "\n",
      "Page 3:\n",
      "  Length: 1826 characters\n",
      "  Preview: Figure 1: The Transformer - model architecture.\n",
      "The Transformer follows this overall architecture us...\n",
      "\n",
      "üí° Tip: Use lazy_load() for PDFs > 100 pages to save memory\n"
     ]
    }
   ],
   "source": [
    "# Lazy loading example\n",
    "if Path(pdf_path).exists():\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    \n",
    "    print(\"üîÑ Lazy loading pages (memory efficient):\")\n",
    "    \n",
    "    # Process first 3 pages only\n",
    "    for i, page in enumerate(loader.lazy_load()):\n",
    "        if i >= 3:  # Only process first 3 pages for demo\n",
    "            break\n",
    "        \n",
    "        print(f\"\\nPage {i+1}:\")\n",
    "        print(f\"  Length: {len(page.page_content)} characters\")\n",
    "        print(f\"  Preview: {page.page_content[:100]}...\")\n",
    "    \n",
    "    print(\"\\nüí° Tip: Use lazy_load() for PDFs > 100 pages to save memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Loading Multiple PDFs from a Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading PDFs from: pdfs/\n",
      "\n",
      "Found 2 PDF files:\n",
      "  - rag.pdf\n",
      "    ‚úÖ Loaded 19 pages\n",
      "  - ragsurvey.pdf\n",
      "    ‚úÖ Loaded 21 pages\n",
      "\n",
      "üìä Total: 40 pages from 2 PDFs\n",
      "\n",
      "Sources:\n",
      "  - ragsurvey.pdf\n",
      "  - rag.pdf\n"
     ]
    }
   ],
   "source": [
    "# Load all PDFs from the pdfs/ directory\n",
    "pdf_directory = \"pdfs\"\n",
    "\n",
    "if Path(pdf_directory).exists():\n",
    "    print(f\"üìÇ Loading PDFs from: {pdf_directory}/\\n\")\n",
    "    \n",
    "    all_documents = []\n",
    "    \n",
    "    # Find all PDF files\n",
    "    pdf_files = list(Path(pdf_directory).glob(\"*.pdf\"))\n",
    "    print(f\"Found {len(pdf_files)} PDF files:\")\n",
    "    \n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"  - {pdf_file.name}\")\n",
    "        \n",
    "        # Load each PDF\n",
    "        loader = PyPDFLoader(str(pdf_file))\n",
    "        docs = loader.load()\n",
    "        all_documents.extend(docs)\n",
    "        \n",
    "        print(f\"    ‚úÖ Loaded {len(docs)} pages\")\n",
    "    \n",
    "    print(f\"\\nüìä Total: {len(all_documents)} pages from {len(pdf_files)} PDFs\")\n",
    "    \n",
    "    # Show unique sources\n",
    "    sources = set(doc.metadata['source'] for doc in all_documents)\n",
    "    print(f\"\\nSources:\")\n",
    "    for source in sources:\n",
    "        print(f\"  - {Path(source).name}\")\n",
    "        \n",
    "else:\n",
    "    print(f\"‚ùå Directory not found: {pdf_directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"csv-loading\"></a>\n",
    "## 4. Loading CSV Files üìä\n",
    "\n",
    "### üî∞ BEGINNER\n",
    "\n",
    "**CSVLoader** converts each row of a CSV file into a separate Document.\n",
    "\n",
    "**Use cases:**\n",
    "- Product catalogs\n",
    "- FAQ databases\n",
    "- Customer records\n",
    "- Any tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSV: sample_data/products.csv\n",
      "\n",
      "‚úÖ Loaded 15 products\n",
      "\n",
      "======================================================================\n",
      "Product 1:\n",
      "======================================================================\n",
      "product_id: 1\n",
      "product_name: Laptop Pro 15\n",
      "category: Electronics\n",
      "description: High-performance laptop with 15-inch display, Intel i7 processor, 16GB RAM, and 512GB SSD. Perfect for professional work and gaming.\n",
      "price: 1299.99\n",
      "stock: 45\n",
      "\n",
      "Source: Laptop Pro 15\n",
      "Row: 0\n",
      "\n",
      "======================================================================\n",
      "Product 2:\n",
      "======================================================================\n",
      "product_id: 2\n",
      "product_name: Wireless Mouse\n",
      "category: Accessories\n",
      "description: Ergonomic wireless mouse with 6 programmable buttons, 2400 DPI optical sensor, and long battery life. Compatible with Windows and Mac.\n",
      "price: 29.99\n",
      "stock: 150\n",
      "\n",
      "Source: Wireless Mouse\n",
      "Row: 1\n",
      "\n",
      "======================================================================\n",
      "Product 3:\n",
      "======================================================================\n",
      "product_id: 3\n",
      "product_name: USB-C Hub\n",
      "category: Accessories\n",
      "description: 7-in-1 USB-C hub with HDMI, USB 3.0 ports, SD card reader, and USB-C power delivery. Ideal for laptops and tablets.\n",
      "price: 49.99\n",
      "stock: 80\n",
      "\n",
      "Source: USB-C Hub\n",
      "Row: 2\n",
      "\n",
      "... and 12 more products\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import CSVLoader\n",
    "\n",
    "# Load the products CSV\n",
    "csv_path = \"sample_data/products.csv\"\n",
    "\n",
    "if Path(csv_path).exists():\n",
    "    print(f\"Loading CSV: {csv_path}\\n\")\n",
    "    \n",
    "    # Create loader\n",
    "    loader = CSVLoader(\n",
    "        file_path=csv_path,\n",
    "        source_column=\"product_name\"  # Which column to use as source in metadata\n",
    "    )\n",
    "    \n",
    "    # Load all rows\n",
    "    documents = loader.load()\n",
    "    \n",
    "    print(f\"‚úÖ Loaded {len(documents)} products\\n\")\n",
    "    \n",
    "    # Inspect first 3 products\n",
    "    for i, doc in enumerate(documents[:3], 1):\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Product {i}:\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(doc.page_content)\n",
    "        print(f\"\\nSource: {doc.metadata['source']}\")\n",
    "        print(f\"Row: {doc.metadata.get('row', 'N/A')}\")\n",
    "        print()\n",
    "    \n",
    "    print(f\"... and {len(documents) - 3} more products\")\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ùå CSV not found: {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéì INTERMEDIATE: Custom CSV Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä CSV with custom configuration:\n",
      "\n",
      "First document source: 1\n",
      "Content preview:\n",
      "product_id: 1\n",
      "product_name: Laptop Pro 15\n",
      "category: Electronics\n",
      "description: High-performance laptop with 15-inch display, Intel i7 processor, 16GB RAM, and 512GB SSD. Perfect for professional work an...\n"
     ]
    }
   ],
   "source": [
    "if Path(csv_path).exists():\n",
    "    # Advanced CSV loading with custom configuration\n",
    "    loader = CSVLoader(\n",
    "        file_path=csv_path,\n",
    "        csv_args={\n",
    "            'delimiter': ',',\n",
    "            'quotechar': '\"',\n",
    "            'fieldnames': None,  # Use first row as headers\n",
    "        },\n",
    "        source_column=\"product_id\"  # Use product_id as source\n",
    "    )\n",
    "    \n",
    "    docs = loader.load()\n",
    "    \n",
    "    # Show how metadata is different\n",
    "    print(\"üìä CSV with custom configuration:\\n\")\n",
    "    print(f\"First document source: {docs[0].metadata['source']}\")\n",
    "    print(f\"Content preview:\\n{docs[0].page_content[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"json-loading\"></a>\n",
    "## 5. Loading JSON Files üîß\n",
    "\n",
    "### üî∞ BEGINNER\n",
    "\n",
    "**JSONLoader** extracts data from JSON files using **jq** syntax (a query language for JSON).\n",
    "\n",
    "**Common use cases:**\n",
    "- API responses\n",
    "- Configuration files\n",
    "- Structured data exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JSON: sample_data/api_response.json\n",
      "\n",
      "‚úÖ Loaded 5 articles\n",
      "\n",
      "üì∞ First Article:\n",
      "Content:\n",
      "{\"id\": \"article_001\", \"title\": \"Introduction to Retrieval-Augmented Generation (RAG)\", \"author\": \"Dr. Sarah Chen\", \"published_date\": \"2025-01-10\", \"category\": \"Machine Learning\", \"tags\": [\"RAG\", \"LLM\", \"NLP\", \"AI\"], \"summary\": \"Retrieval-Augmented Generation (RAG) is a powerful technique that combines information retrieval with large language models to generate more accurate and contextual responses.\", \"content\": \"RAG systems work by first retrieving relevant documents from a knowledge base, then using those documents as context for a language model to generate responses. This approach significantly reduces hallucinations and provides more factual, grounded outputs. The architecture typically consists of three main components: a document store, an embedding model for semantic search, and a language model for generation.\", \"reading_time\": \"5 minutes\", \"views\": 15420, \"likes\": 892}\n",
      "\n",
      "Metadata: {'source': '/Users/sourangshupal/Downloads/simple-rag-langchain/sample_data/api_response.json', 'seq_num': 1}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import JSONLoader\n",
    "\n",
    "# Load the API response JSON\n",
    "json_path = \"sample_data/api_response.json\"\n",
    "\n",
    "if Path(json_path).exists():\n",
    "    print(f\"Loading JSON: {json_path}\\n\")\n",
    "    \n",
    "    # Create loader\n",
    "    # jq_schema tells us where to find the content in the JSON\n",
    "    # .articles[] means: get all items from the 'articles' array\n",
    "    loader = JSONLoader(\n",
    "        file_path=json_path,\n",
    "        jq_schema=\".articles[]\",  # Extract each article\n",
    "        text_content=False  # Return full JSON for each article\n",
    "    )\n",
    "    \n",
    "    # Load articles\n",
    "    documents = loader.load()\n",
    "    \n",
    "    print(f\"‚úÖ Loaded {len(documents)} articles\\n\")\n",
    "    \n",
    "    # Inspect first article\n",
    "    print(\"üì∞ First Article:\")\n",
    "    print(f\"Content:\\n{documents[0].page_content}\\n\")\n",
    "    print(f\"Metadata: {documents[0].metadata}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ùå JSON not found: {json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 723ms\u001b[0m\u001b[0m                                          \u001b[0m\n",
      "\u001b[2K\u001b[37m‚†º\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)                                                   \n",
      "\u001b[2K\u001b[1A\u001b[37m‚†º\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----\u001b[0m\u001b[0m     0 B/415.38 KiB                    \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†º\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----\u001b[0m\u001b[0m 14.92 KiB/415.38 KiB                  \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†º\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----\u001b[0m\u001b[0m 30.92 KiB/415.38 KiB                  \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†º\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----\u001b[0m\u001b[0m 46.92 KiB/415.38 KiB                  \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†º\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----\u001b[0m\u001b[0m 62.92 KiB/415.38 KiB                  \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†º\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----\u001b[0m\u001b[0m 78.92 KiB/415.38 KiB                  \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†º\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----\u001b[0m\u001b[0m 94.92 KiB/415.38 KiB                  \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†º\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----\u001b[0m\u001b[0m 110.92 KiB/415.38 KiB                 \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†º\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----\u001b[0m\u001b[0m 126.92 KiB/415.38 KiB                 \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†º\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----\u001b[0m\u001b[0m 142.92 KiB/415.38 KiB                 \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†º\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----\u001b[0m\u001b[0m 158.92 KiB/415.38 KiB                 \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†º\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----\u001b[0m\u001b[0m 174.92 KiB/415.38 KiB                 \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†º\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----\u001b[0m\u001b[0m 190.92 KiB/415.38 KiB                 \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†º\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----\u001b[0m\u001b[0m 206.92 KiB/415.38 KiB                 \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†º\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----\u001b[0m\u001b[0m 222.92 KiB/415.38 KiB                 \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†º\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----\u001b[0m\u001b[0m 238.92 KiB/415.38 KiB                 \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†º\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----\u001b[0m\u001b[0m 254.92 KiB/415.38 KiB                 \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†º\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----\u001b[0m\u001b[0m 267.93 KiB/415.38 KiB                 \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†º\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----\u001b[0m\u001b[0m 283.93 KiB/415.38 KiB                 \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†º\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----\u001b[0m\u001b[0m 299.93 KiB/415.38 KiB                 \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†º\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----\u001b[0m\u001b[0m 315.93 KiB/415.38 KiB                 \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†º\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----\u001b[0m\u001b[0m 331.93 KiB/415.38 KiB                 \u001b[1A\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 791ms\u001b[0m\u001b[0m                                                  \u001b[1A\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 2ms\u001b[0m\u001b[0m                                  \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjq\u001b[0m\u001b[2m==1.10.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install jq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéì INTERMEDIATE: Extracting Specific Fields from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Path(json_path).exists():\n",
    "    # Extract only the article content field\n",
    "    loader = JSONLoader(\n",
    "        file_path=json_path,\n",
    "        jq_schema=\".articles[].content\",  # Get only 'content' field\n",
    "        text_content=True  # Treat as plain text\n",
    "    )\n",
    "    \n",
    "    docs = loader.load()\n",
    "    \n",
    "    print(\"üìù Extracted Article Contents Only:\\n\")\n",
    "    for i, doc in enumerate(docs[:2], 1):\n",
    "        print(f\"{i}. {doc.page_content[:150]}...\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üî∞ BEGINNER TIP: Understanding jq Syntax\n",
    "\n",
    "**jq** is like a GPS for JSON:\n",
    "\n",
    "| jq Expression | Meaning |\n",
    "|--------------|----------|\n",
    "| `.` | Root of JSON |\n",
    "| `.articles` | Get the 'articles' field |\n",
    "| `.articles[]` | Get all items in 'articles' array |\n",
    "| `.articles[0]` | Get first item in 'articles' array |\n",
    "| `.articles[].title` | Get 'title' from each article |\n",
    "\n",
    "**Example:**\n",
    "```json\n",
    "{\n",
    "  \"articles\": [\n",
    "    {\"title\": \"Article 1\", \"content\": \"...\"},\n",
    "    {\"title\": \"Article 2\", \"content\": \"...\"}\n",
    "  ]\n",
    "}\n",
    "```\n",
    "- `.articles[]` ‚Üí Returns both articles\n",
    "- `.articles[].title` ‚Üí Returns [\"Article 1\", \"Article 2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"html-loading\"></a>\n",
    "## 6. Loading Web Pages (HTML) üåê\n",
    "\n",
    "### üî∞ BEGINNER\n",
    "\n",
    "**WebBaseLoader** scrapes web pages and extracts text content.\n",
    "\n",
    "**Important:** Only works with **static HTML**. For JavaScript-rendered sites, you'd need Playwright or Selenium.\n",
    "\n",
    "### Example 1: Loading a Local HTML File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m51 packages\u001b[0m \u001b[2min 1.26s\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)                                                   \n",
      "\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)----\u001b[0m\u001b[0m     0 B/105.74 KiB                    \u001b[1A\n",
      "\u001b[2mclick     \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/105.74 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)----\u001b[0m\u001b[0m     0 B/318.94 KiB                    \u001b[2A\n",
      "\u001b[2mclick     \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 16.00 KiB/105.74 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)----\u001b[0m\u001b[0m     0 B/318.94 KiB                    \u001b[2A\n",
      "\u001b[2mclick     \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 16.00 KiB/105.74 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)----\u001b[0m\u001b[0m 14.92 KiB/318.94 KiB                  \u001b[2A\n",
      "\u001b[2mclick     \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 32.00 KiB/105.74 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)----\u001b[0m\u001b[0m 14.92 KiB/318.94 KiB                  \u001b[2A\n",
      "\u001b[2mclick     \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 48.00 KiB/105.74 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)----\u001b[0m\u001b[0m 14.92 KiB/318.94 KiB                  \u001b[2A\n",
      "\u001b[2mclick     \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 63.79 KiB/105.74 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)----\u001b[0m\u001b[0m 14.92 KiB/318.94 KiB                  \u001b[2A\n",
      "\u001b[2mclick     \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 63.79 KiB/105.74 KiB\n",
      "\u001b[2mpython-iso639\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/163.79 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)----\u001b[0m\u001b[0m 14.92 KiB/318.94 KiB                  \u001b[3A\n",
      "\u001b[2mclick     \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 63.79 KiB/105.74 KiB\n",
      "\u001b[2mpython-iso639\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/163.79 KiB\n",
      "\u001b[2mpypdf     \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 14.92 KiB/318.94 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)------\u001b[0m\u001b[0m     0 B/6.89 MiB                    \u001b[4A\n",
      "\u001b[2mclick     \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 63.79 KiB/105.74 KiB\n",
      "\u001b[2mpython-iso639\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/163.79 KiB\n",
      "\u001b[2munstructured-client\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/202.99 KiB\n",
      "\u001b[2mpypdf     \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 14.92 KiB/318.94 KiB\n",
      "\u001b[2K\u001b[5A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)------\u001b[0m\u001b[0m     0 B/6.89 MiB                    \u001b[5A\n",
      "\u001b[2mclick     \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 63.79 KiB/105.74 KiB\n",
      "\u001b[2mpython-iso639\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/163.79 KiB\n",
      "\u001b[2munstructured-client\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/202.99 KiB\n",
      "\u001b[2mpypdf     \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 14.92 KiB/318.94 KiB\n",
      "\u001b[2munstructured\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/1.70 MiB\n",
      "\u001b[2K\u001b[6A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)------\u001b[0m\u001b[0m     0 B/6.89 MiB                    \u001b[6A\n",
      "\u001b[2mclick     \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 63.79 KiB/105.74 KiB\n",
      "\u001b[2mpython-iso639\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/163.79 KiB\n",
      "\u001b[2munstructured-client\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/202.99 KiB\n",
      "\u001b[2mpypdf     \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 14.92 KiB/318.94 KiB\n",
      "\u001b[2mrapidfuzz \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/1.32 MiB\n",
      "\u001b[2munstructured\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/1.70 MiB\n",
      "\u001b[2K\u001b[7A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)------\u001b[0m\u001b[0m     0 B/6.89 MiB                    \u001b[7A\n",
      "\u001b[2mwrapt     \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/60.24 KiB\n",
      "\u001b[2mclick     \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 63.79 KiB/105.74 KiB\n",
      "\u001b[2mpython-iso639\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/163.79 KiB\n",
      "\u001b[2munstructured-client\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/202.99 KiB\n",
      "\u001b[2mpypdf     \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 14.92 KiB/318.94 KiB\n",
      "\u001b[2mrapidfuzz \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/1.32 MiB\n",
      "\u001b[2munstructured\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/1.70 MiB\n",
      "\u001b[2K\u001b[8A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)------\u001b[0m\u001b[0m     0 B/6.89 MiB                    \u001b[8A\n",
      "\u001b[2mwrapt     \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/60.24 KiB\n",
      "\u001b[2mclick     \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 63.79 KiB/105.74 KiB\n",
      "\u001b[2mpython-iso639\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/163.79 KiB\n",
      "\u001b[2munstructured-client\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/202.99 KiB\n",
      "\u001b[2mpypdf     \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 30.92 KiB/318.94 KiB\n",
      "\u001b[2mrapidfuzz \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/1.32 MiB\n",
      "\u001b[2munstructured\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/1.70 MiB\n",
      "\u001b[2K\u001b[8A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)------\u001b[0m\u001b[0m     0 B/6.89 MiB                    \u001b[8A\n",
      "\u001b[2mwrapt     \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/60.24 KiB\n",
      "\u001b[2mclick     \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 79.79 KiB/105.74 KiB\n",
      "\u001b[2mpython-iso639\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/163.79 KiB\n",
      "\u001b[2munstructured-client\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/202.99 KiB\n",
      "\u001b[2mpypdf     \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 30.92 KiB/318.94 KiB\n",
      "\u001b[2mrapidfuzz \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/1.32 MiB\n",
      "\u001b[2munstructured\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/1.70 MiB\n",
      "\u001b[2K\u001b[8A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)------\u001b[0m\u001b[0m     0 B/6.89 MiB                    \u001b[8A\n",
      "\u001b[2mwrapt     \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/60.24 KiB\n",
      "\u001b[2mclick     \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 79.79 KiB/105.74 KiB\n",
      "\u001b[2mpython-iso639\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/163.79 KiB\n",
      "\u001b[2munstructured-client\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/202.99 KiB\n",
      "\u001b[2mpypdf     \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 46.92 KiB/318.94 KiB\n",
      "\u001b[2mrapidfuzz \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/1.32 MiB\n",
      "\u001b[2munstructured\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/1.70 MiB\n",
      "\u001b[2K\u001b[8A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)------\u001b[0m\u001b[0m     0 B/6.89 MiB                    \u001b[8A\n",
      "\u001b[2mwrapt     \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/60.24 KiB\n",
      "\u001b[2mclick     \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 95.79 KiB/105.74 KiB\n",
      "\u001b[2mpython-iso639\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/163.79 KiB\n",
      "\u001b[2munstructured-client\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/202.99 KiB\n",
      "\u001b[2mpypdf     \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 46.92 KiB/318.94 KiB\n",
      "\u001b[2mrapidfuzz \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/1.32 MiB\n",
      "\u001b[2munstructured\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/1.70 MiB\n",
      "\u001b[2K\u001b[8A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)------\u001b[0m\u001b[0m     0 B/6.89 MiB                    \u001b[8A\n",
      "\u001b[2mwrapt     \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/60.24 KiB\n",
      "\u001b[2mpython-iso639\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/163.79 KiB\n",
      "\u001b[2munstructured-client\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/202.99 KiB\n",
      "\u001b[2mpypdf     \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 75.42 KiB/318.94 KiB\n",
      "\u001b[2mrapidfuzz \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/1.32 MiB\n",
      "\u001b[2munstructured\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/1.70 MiB\n",
      "\u001b[2K\u001b[7A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)------\u001b[0m\u001b[0m     0 B/6.89 MiB                    \u001b[7A\n",
      "\u001b[2mwrapt     \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 16.00 KiB/60.24 KiB\n",
      "\u001b[2mpython-iso639\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 31.89 KiB/163.79 KiB\n",
      "\u001b[2munstructured-client\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.00 KiB/202.99 KiB\n",
      "\u001b[2mpypdf     \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 91.42 KiB/318.94 KiB\n",
      "\u001b[2mrapidfuzz \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/1.32 MiB\n",
      "\u001b[2munstructured\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/1.70 MiB\n",
      "\u001b[2K\u001b[7A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)------\u001b[0m\u001b[0m 32.00 KiB/6.89 MiB                  \u001b[7A\n",
      "\u001b[2mpython-iso639\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 61.34 KiB/163.79 KiB\n",
      "\u001b[2munstructured-client\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 48.00 KiB/202.99 KiB\n",
      "\u001b[2mpypdf     \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 123.42 KiB/318.94 KiB\n",
      "\u001b[2mrapidfuzz \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 61.65 KiB/1.32 MiB\n",
      "\u001b[2munstructured\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 48.00 KiB/1.70 MiB\n",
      "\u001b[2K\u001b[6A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)------\u001b[0m\u001b[0m 61.40 KiB/6.89 MiB                  \u001b[6A\n",
      "\u001b[2mpython-iso639\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 156.17 KiB/163.79 KiB\n",
      "\u001b[2munstructured-client\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 157.83 KiB/202.99 KiB\n",
      "\u001b[2mpypdf     \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 203.42 KiB/318.94 KiB\n",
      "\u001b[2mrapidfuzz \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 125.65 KiB/1.32 MiB\n",
      "\u001b[2munstructured\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 125.93 KiB/1.70 MiB\n",
      "\u001b[2K\u001b[6A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)------\u001b[0m\u001b[0m 157.40 KiB/6.89 MiB                 \u001b[6A\n",
      "\u001b[2munstructured-client\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 173.83 KiB/202.99 KiB\n",
      "\u001b[2mpypdf     \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 203.42 KiB/318.94 KiB\n",
      "\u001b[2mrapidfuzz \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 141.65 KiB/1.32 MiB\n",
      "\u001b[2munstructured\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 125.93 KiB/1.70 MiB\n",
      "\u001b[2K\u001b[5A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)------\u001b[0m\u001b[0m 157.40 KiB/6.89 MiB                 \u001b[5A\n",
      "\u001b[2mpypdf     \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 235.42 KiB/318.94 KiB\n",
      "\u001b[2mrapidfuzz \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 165.91 KiB/1.32 MiB\n",
      "\u001b[2munstructured\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 157.93 KiB/1.70 MiB\n",
      "\u001b[2K\u001b[4A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)------\u001b[0m\u001b[0m 189.40 KiB/6.89 MiB                 \u001b[4A\n",
      "\u001b[2mrapidfuzz \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 253.65 KiB/1.32 MiB\n",
      "\u001b[2munstructured\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 237.93 KiB/1.70 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)------\u001b[0m\u001b[0m 317.40 KiB/6.89 MiB                 \u001b[3A\n",
      "\u001b[2mrapidfuzz \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 557.65 KiB/1.32 MiB\n",
      "\u001b[2munstructured\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 541.93 KiB/1.70 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)------\u001b[0m\u001b[0m 621.40 KiB/6.89 MiB                 \u001b[3A\n",
      "\u001b[2mrapidfuzz \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 1.07 MiB/1.32 MiB\n",
      "\u001b[2munstructured\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 1.12 MiB/1.70 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m‚†π\u001b[0m \u001b[2mPreparing packages...\u001b[0m (5/8)------\u001b[0m\u001b[0m 1.12 MiB/6.89 MiB                   \u001b[3A\n",
      "\u001b[2munstructured\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 1.41 MiB/1.70 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m‚†π\u001b[0m \u001b[2mPreparing packages...\u001b[0m (5/8)------\u001b[0m\u001b[0m 1.38 MiB/6.89 MiB                   \u001b[2A\n",
      "\u001b[2munstructured\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 1.47 MiB/1.70 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m‚†π\u001b[0m \u001b[2mPreparing packages...\u001b[0m (5/8)------\u001b[0m\u001b[0m 1.41 MiB/6.89 MiB                   \u001b[2A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†π\u001b[0m \u001b[2mPreparing packages...\u001b[0m (5/8)------\u001b[0m\u001b[0m 1.84 MiB/6.89 MiB                   \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†π\u001b[0m \u001b[2mPreparing packages...\u001b[0m (5/8)------\u001b[0m\u001b[0m 2.62 MiB/6.89 MiB                   \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†π\u001b[0m \u001b[2mPreparing packages...\u001b[0m (5/8)------\u001b[0m\u001b[0m 4.39 MiB/6.89 MiB                   \u001b[1A\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m8 packages\u001b[0m \u001b[2min 430ms\u001b[0m\u001b[0m                                                 \u001b[1A\n",
      "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 10ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m20 packages\u001b[0m \u001b[2min 62ms\u001b[0m\u001b[0m                               \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maiofiles\u001b[0m\u001b[2m==25.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mbackoff\u001b[0m\u001b[2m==2.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mclick\u001b[0m\u001b[2m==8.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcryptography\u001b[0m\u001b[2m==46.0.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1memoji\u001b[0m\u001b[2m==2.15.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfiletype\u001b[0m\u001b[2m==1.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhtml5lib\u001b[0m\u001b[2m==1.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjoblib\u001b[0m\u001b[2m==1.5.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangdetect\u001b[0m\u001b[2m==1.0.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlxml\u001b[0m\u001b[2m==6.0.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnltk\u001b[0m\u001b[2m==3.9.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1molefile\u001b[0m\u001b[2m==0.47\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mpypdf\u001b[0m\u001b[2m==6.1.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpypdf\u001b[0m\u001b[2m==6.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-iso639\u001b[0m\u001b[2m==2025.11.11\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-magic\u001b[0m\u001b[2m==0.4.27\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-oxmsg\u001b[0m\u001b[2m==0.0.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrapidfuzz\u001b[0m\u001b[2m==3.14.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1munstructured\u001b[0m\u001b[2m==0.18.20\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1munstructured-client\u001b[0m\u001b[2m==0.42.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwrapt\u001b[0m\u001b[2m==2.0.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading HTML: sample_data/blog_post.html\n",
      "\n",
      "‚úÖ Loaded 1 document(s)\n",
      "\n",
      "üìÑ Content length: 7197 characters\n",
      "\n",
      "üìù First 500 characters:\n",
      "Building Intelligent Applications with RAG\n",
      "\n",
      "By Dr. Amanda Foster | January 15, 2025 | 12 min read\n",
      "\n",
      "Introduction\n",
      "\n",
      "In the rapidly evolving landscape of artificial intelligence, Retrieval-Augmented Generation (RAG) has emerged as a game-changing approach for building intelligent applications. Unlike traditional chatbots that rely solely on the knowledge embedded in their training data, RAG systems combine the power of information retrieval with language generation to produce more accurate, contextu...\n",
      "\n",
      "üîç Metadata: {'source': 'sample_data/blog_post.html'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import UnstructuredHTMLLoader\n",
    "\n",
    "# Load our sample blog post\n",
    "html_path = \"sample_data/blog_post.html\"\n",
    "\n",
    "if Path(html_path).exists():\n",
    "    print(f\"Loading HTML: {html_path}\\n\")\n",
    "    \n",
    "    # For local files, we need to use file:// protocol\n",
    "    file_url = f\"file://{Path(html_path).absolute()}\"\n",
    "    \n",
    "    # Create loader\n",
    "    loader = UnstructuredHTMLLoader(html_path)\n",
    "    \n",
    "    # Load the page\n",
    "    documents = loader.load()\n",
    "    \n",
    "    print(f\"‚úÖ Loaded {len(documents)} document(s)\\n\")\n",
    "    \n",
    "    # Inspect content\n",
    "    doc = documents[0]\n",
    "    print(f\"üìÑ Content length: {len(doc.page_content)} characters\")\n",
    "    print(f\"\\nüìù First 500 characters:\\n{doc.page_content[:500]}...\")\n",
    "    print(f\"\\nüîç Metadata: {doc.metadata}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ùå HTML not found: {html_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéì INTERMEDIATE: Loading Multiple URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 pages\n",
      "  - https://python.langchain.com/docs/introduction/\n",
      "  - https://python.langchain.com/docs/expression_language/\n",
      "üí° WebBaseLoader Example:\n",
      "\n",
      "To load web pages, use:\n",
      "loader = WebBaseLoader([\n",
      "    \"https://example.com/page1\",\n",
      "    \"https://example.com/page2\"\n",
      "])\n",
      "\n",
      "‚ö†Ô∏è Note: Only works with static HTML (no JavaScript rendering)\n"
     ]
    }
   ],
   "source": [
    "# Example: Load multiple web pages at once\n",
    "# NOTE: This will actually make HTTP requests, so we're using examples\n",
    "\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "#Uncomment to try with real websites:\n",
    "urls = [\n",
    "    \"https://python.langchain.com/docs/introduction/\",\n",
    "    \"https://python.langchain.com/docs/expression_language/\"\n",
    "]\n",
    "\n",
    "loader = WebBaseLoader(urls)\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"Loaded {len(docs)} pages\")\n",
    "for doc in docs:\n",
    "    print(f\"  - {doc.metadata['source']}\")\n",
    "\n",
    "print(\"üí° WebBaseLoader Example:\")\n",
    "print(\"\\nTo load web pages, use:\")\n",
    "print(\"\"\"loader = WebBaseLoader([\n",
    "    \"https://example.com/page1\",\n",
    "    \"https://example.com/page2\"\n",
    "])\"\"\")\n",
    "print(\"\\n‚ö†Ô∏è Note: Only works with static HTML (no JavaScript rendering)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üìÑ LOADED DOCUMENTS CONTENT\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "üìÑ PAGE 1: https://python.langchain.com/docs/introduction/\n",
      "================================================================================\n",
      "\n",
      "üìù Content Preview (first 1000 chars):\n",
      "LangChain overview - Docs by LangChainSkip to main contentDocs by LangChain home pageLangChain + LangGraphSearch...‚åòKGitHubTry LangSmithTry LangSmithSearch...NavigationLangChain overviewLangChainLangGraphDeep AgentsIntegrationsLearnReferenceContributePythonOverviewLangChain v1.0Release notesMigration guideGet startedInstallQuickstartPhilosophyCore componentsAgentsModelsMessagesToolsShort-term memoryStreamingStructured outputMiddlewareOverviewBuilt-in middlewareCustom middlewareAdvanced usageGuardrailsRuntimeContext engineeringModel Context Protocol (MCP)Human-in-the-loopMulti-agentRetrievalLong-term memoryUse in productionStudioTestDeployAgent Chat UIObservabilityOn this page Install Create an agent Core benefitsLangChain overviewCopy pageCopy pageLangChain v1.0 is now available!For a complete list of changes and instructions on how to upgrade your code, see the release notes and migration guide.If you encounter any issues or have feedback, please open an issue so we can improve. To vi\n",
      "\n",
      "... [Total length: 3797 characters]\n",
      "\n",
      "üîç Metadata:\n",
      "   source: https://python.langchain.com/docs/introduction/\n",
      "   title: LangChain overview - Docs by LangChain\n",
      "   language: en\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìÑ PAGE 2: https://python.langchain.com/docs/expression_language/\n",
      "================================================================================\n",
      "\n",
      "üìù Content Preview (first 1000 chars):\n",
      "LangChain overview - Docs by LangChainSkip to main contentDocs by LangChain home pageLangChain + LangGraphSearch...‚åòKGitHubTry LangSmithTry LangSmithSearch...NavigationLangChain overviewLangChainLangGraphDeep AgentsIntegrationsLearnReferenceContributePythonOverviewLangChain v1.0Release notesMigration guideGet startedInstallQuickstartPhilosophyCore componentsAgentsModelsMessagesToolsShort-term memoryStreamingStructured outputMiddlewareOverviewBuilt-in middlewareCustom middlewareAdvanced usageGuardrailsRuntimeContext engineeringModel Context Protocol (MCP)Human-in-the-loopMulti-agentRetrievalLong-term memoryUse in productionStudioTestDeployAgent Chat UIObservabilityOn this page Install Create an agent Core benefitsLangChain overviewCopy pageCopy pageLangChain v1.0 is now available!For a complete list of changes and instructions on how to upgrade your code, see the release notes and migration guide.If you encounter any issues or have feedback, please open an issue so we can improve. To vi\n",
      "\n",
      "... [Total length: 3797 characters]\n",
      "\n",
      "üîç Metadata:\n",
      "   source: https://python.langchain.com/docs/expression_language/\n",
      "   title: LangChain overview - Docs by LangChain\n",
      "   language: en\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìñ FULL CONTENT OF PAGE 1\n",
      "================================================================================\n",
      "LangChain overview - Docs by LangChainSkip to main contentDocs by LangChain home pageLangChain + LangGraphSearch...‚åòKGitHubTry LangSmithTry LangSmithSearch...NavigationLangChain overviewLangChainLangGraphDeep AgentsIntegrationsLearnReferenceContributePythonOverviewLangChain v1.0Release notesMigration guideGet startedInstallQuickstartPhilosophyCore componentsAgentsModelsMessagesToolsShort-term memoryStreamingStructured outputMiddlewareOverviewBuilt-in middlewareCustom middlewareAdvanced usageGuardrailsRuntimeContext engineeringModel Context Protocol (MCP)Human-in-the-loopMulti-agentRetrievalLong-term memoryUse in productionStudioTestDeployAgent Chat UIObservabilityOn this page Install Create an agent Core benefitsLangChain overviewCopy pageCopy pageLangChain v1.0 is now available!For a complete list of changes and instructions on how to upgrade your code, see the release notes and migration guide.If you encounter any issues or have feedback, please open an issue so we can improve. To view v0.x documentation, go to the archived content.\n",
      "LangChain is the easiest way to start building agents and applications powered by LLMs. With under 10 lines of code, you can connect to OpenAI, Anthropic, Google, and more. LangChain provides a pre-built agent architecture and model integrations to help you get started quickly and seamlessly incorporate LLMs into your agents and applications.\n",
      "We recommend you use LangChain if you want to quickly build agents and autonomous applications. Use LangGraph, our low-level agent orchestration framework and runtime, when you have more advanced needs that require a combination of deterministic and agentic workflows, heavy customization, and carefully controlled latency.\n",
      "LangChain agents are built on top of LangGraph in order to provide durable execution, streaming, human-in-the-loop, persistence, and more. You do not need to know LangGraph for basic LangChain agent usage.\n",
      "‚Äã Install\n",
      "pipuvCopyAsk AIpip install -U langchain\n",
      "# Requires Python 3.10+\n",
      "\n",
      "‚Äã Create an agent\n",
      "CopyAsk AI# pip install -qU \"langchain[anthropic]\" to call the model\n",
      "\n",
      "from langchain.agents import create_agent\n",
      "\n",
      "def get_weather(city: str) -> str:\n",
      "    \"\"\"Get weather for a given city.\"\"\"\n",
      "    return f\"It's always sunny in {city}!\"\n",
      "\n",
      "agent = create_agent(\n",
      "    model=\"claude-sonnet-4-5-20250929\",\n",
      "    tools=[get_weather],\n",
      "    system_prompt=\"You are a helpful assistant\",\n",
      ")\n",
      "\n",
      "# Run the agent\n",
      "agent.invoke(\n",
      "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\n",
      ")\n",
      "\n",
      "‚Äã Core benefits\n",
      "Standard model interfaceDifferent providers have unique APIs for interacting with models, including the format of responses. LangChain standardizes how you interact with models so that you can seamlessly swap providers and avoid lock-in.Learn moreEasy to use, highly flexible agentLangChain‚Äôs agent abstraction is designed to be easy to get started with, letting you build a simple agent in under 10 lines of code. But it also provides enough flexibility to allow you to do all the context engineering your heart desires.Learn moreBuilt on top of LangGraphLangChain‚Äôs agents are built on top of LangGraph. This allows us to take advantage of LangGraph‚Äôs durable execution, human-in-the-loop support, persistence, and more.Learn moreDebug with LangSmithGain deep visibility into complex agent behavior with visualization tools that trace execution paths, capture state transitions, and provide detailed runtime metrics.Learn more\n",
      "\n",
      "Edit the source of this page on GitHub.\n",
      "Connect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.Was this page helpful?YesNoWhat's new in v1Next‚åòIDocs by LangChain home pagegithubxlinkedinyoutubeResourcesForumChangelogLangChain AcademyTrust CenterCompanyAboutCareersBloggithubxlinkedinyoutubePowered by Mintlify\n"
     ]
    }
   ],
   "source": [
    "# Print content from both loaded pages\n",
    "print(\"=\"*80)\n",
    "print(\"üìÑ LOADED DOCUMENTS CONTENT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, doc in enumerate(docs, 1):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üìÑ PAGE {i}: {doc.metadata['source']}\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    # Print first 1000 characters of content\n",
    "    print(f\"\\nüìù Content Preview (first 1000 chars):\")\n",
    "    print(doc.page_content[:1000])\n",
    "    print(f\"\\n... [Total length: {len(doc.page_content)} characters]\")\n",
    "\n",
    "    # Print metadata\n",
    "    print(f\"\\nüîç Metadata:\")\n",
    "    for key, value in doc.metadata.items():\n",
    "        print(f\"   {key}: {value}\")\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Full content of a specific page\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìñ FULL CONTENT OF PAGE 1\")\n",
    "print(\"=\"*80)\n",
    "print(docs[0].page_content)\n",
    "\n",
    "#  Or for a simpler version to just see the content:\n",
    "\n",
    "# Simple version - print both pages\n",
    "# for i, doc in enumerate(docs, 1):\n",
    "#     print(f\"\\n{'='*80}\")\n",
    "#     print(f\"PAGE {i}: {doc.metadata['source']}\")\n",
    "#     print(f\"{'='*80}\\n\")\n",
    "#     print(doc.page_content)\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"text-loading\"></a>\n",
    "## 7. Loading Text and Markdown Files üìù\n",
    "\n",
    "### üî∞ BEGINNER\n",
    "\n",
    "For simple text files, use **TextLoader**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading text file: sample_data/notes.txt\n",
      "\n",
      "‚úÖ Loaded 1 document\n",
      "\n",
      "üìÑ Content length: 8567 characters\n",
      "\n",
      "üìù First 300 characters:\n",
      "LANGCHAIN STUDY NOTES - RAG IMPLEMENTATION\n",
      "==========================================\n",
      "\n",
      "Date: January 15, 2025\n",
      "Topic: Retrieval-Augmented Generation with LangChain 1.0+\n",
      "\n",
      "\n",
      "CORE CONCEPTS\n",
      "-------------\n",
      "\n",
      "1. Document Object Structure\n",
      "   - page_content: The actual text content\n",
      "   - metadata: Dictionary wit...\n",
      "\n",
      "üîç Metadata: {'source': 'sample_data/notes.txt'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# Load the notes.txt file\n",
    "txt_path = \"sample_data/notes.txt\"\n",
    "\n",
    "if Path(txt_path).exists():\n",
    "    print(f\"Loading text file: {txt_path}\\n\")\n",
    "    \n",
    "    # Create loader\n",
    "    loader = TextLoader(txt_path, encoding=\"utf-8\")\n",
    "    \n",
    "    # Load the file\n",
    "    documents = loader.load()\n",
    "    \n",
    "    print(f\"‚úÖ Loaded {len(documents)} document\\n\")\n",
    "    \n",
    "    doc = documents[0]\n",
    "    print(f\"üìÑ Content length: {len(doc.page_content)} characters\")\n",
    "    print(f\"\\nüìù First 300 characters:\\n{doc.page_content[:300]}...\")\n",
    "    print(f\"\\nüîç Metadata: {doc.metadata}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ùå Text file not found: {txt_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markdown Files\n",
    "\n",
    "For Markdown files, use **UnstructuredMarkdownLoader** (preserves structure):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading markdown: README.md\n",
      "\n",
      "‚ö†Ô∏è UnstructuredMarkdownLoader requires additional dependencies\n",
      "   Install with: pip install unstructured\n",
      "\n",
      "   For now, using TextLoader:\n",
      "   ‚úÖ Loaded with TextLoader: 13194 chars\n"
     ]
    }
   ],
   "source": [
    "# Check if README.md exists\n",
    "readme_path = \"README.md\"\n",
    "\n",
    "if Path(readme_path).exists():\n",
    "    try:\n",
    "        from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "        \n",
    "        print(f\"Loading markdown: {readme_path}\\n\")\n",
    "        \n",
    "        loader = UnstructuredMarkdownLoader(readme_path)\n",
    "        docs = loader.load()\n",
    "        \n",
    "        print(f\"‚úÖ Loaded {len(docs)} document(s)\")\n",
    "        print(f\"\\nFirst 200 chars:\\n{docs[0].page_content[:200]}...\")\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"‚ö†Ô∏è UnstructuredMarkdownLoader requires additional dependencies\")\n",
    "        print(\"   Install with: pip install unstructured\")\n",
    "        print(\"\\n   For now, using TextLoader:\")\n",
    "        \n",
    "        loader = TextLoader(readme_path)\n",
    "        docs = loader.load()\n",
    "        print(f\"   ‚úÖ Loaded with TextLoader: {len(docs[0].page_content)} chars\")\n",
    "else:\n",
    "    print(f\"‚ÑπÔ∏è No README.md found in current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"batch-loading\"></a>\n",
    "## 8. Batch Loading with DirectoryLoader üìÇ\n",
    "\n",
    "### üî∞ BEGINNER\n",
    "\n",
    "**DirectoryLoader** loads all files from a directory automatically.\n",
    "\n",
    "Perfect for:\n",
    "- Loading entire document libraries\n",
    "- Processing multiple files at once\n",
    "- Building knowledge bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading all text files from: sample_data/\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 1140.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Loaded 1 text file(s)\n",
      "\n",
      "  - sample_data/notes.txt (8567 chars)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "# Load all files from sample_data directory\n",
    "data_dir = \"sample_data\"\n",
    "\n",
    "if Path(data_dir).exists():\n",
    "    print(f\"üìÇ Loading all text files from: {data_dir}/\\n\")\n",
    "    \n",
    "    # Create loader for .txt files only\n",
    "    loader = DirectoryLoader(\n",
    "        data_dir,\n",
    "        glob=\"*.txt\",  # Pattern to match files\n",
    "        loader_cls=TextLoader,  # Use TextLoader for each file\n",
    "        show_progress=True  # Show progress bar\n",
    "    )\n",
    "    \n",
    "    # Load all matching files\n",
    "    documents = loader.load()\n",
    "    \n",
    "    print(f\"\\n‚úÖ Loaded {len(documents)} text file(s)\\n\")\n",
    "    \n",
    "    # Show sources\n",
    "    for doc in documents:\n",
    "        print(f\"  - {doc.metadata['source']} ({len(doc.page_content)} chars)\")\n",
    "        \n",
    "else:\n",
    "    print(f\"‚ùå Directory not found: {data_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéì INTERMEDIATE: Loading Multiple File Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading from: sample_data\n",
      "\n",
      "  ‚úÖ TXT: notes.txt\n",
      "  ‚úÖ CSV: products.csv (15 rows)\n",
      "  ‚úÖ JSON: api_response.json\n",
      "\n",
      "üìä Total: 17 documents loaded\n",
      "\n",
      "üìà Summary:\n",
      "   Files loaded: 3\n",
      "   Total documents: 17\n"
     ]
    }
   ],
   "source": [
    "# Advanced: Load all files from a directory (mixed types)\n",
    "# This function handles different file types intelligently\n",
    "\n",
    "def load_all_documents(directory: str) -> list:\n",
    "    \"\"\"\n",
    "    Load documents from multiple file formats in a directory.\n",
    "    \n",
    "    Supports: PDF, TXT, CSV, JSON, HTML\n",
    "    \"\"\"\n",
    "    all_docs = []\n",
    "    directory_path = Path(directory)\n",
    "    \n",
    "    if not directory_path.exists():\n",
    "        print(f\"‚ùå Directory not found: {directory}\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"üìÇ Loading from: {directory}\\n\")\n",
    "    \n",
    "    # Load PDFs\n",
    "    pdf_files = list(directory_path.glob(\"*.pdf\"))\n",
    "    for pdf in pdf_files:\n",
    "        loader = PyPDFLoader(str(pdf))\n",
    "        docs = loader.load()\n",
    "        all_docs.extend(docs)\n",
    "        print(f\"  ‚úÖ PDF: {pdf.name} ({len(docs)} pages)\")\n",
    "    \n",
    "    # Load TXT files\n",
    "    txt_files = list(directory_path.glob(\"*.txt\"))\n",
    "    for txt in txt_files:\n",
    "        loader = TextLoader(str(txt))\n",
    "        docs = loader.load()\n",
    "        all_docs.extend(docs)\n",
    "        print(f\"  ‚úÖ TXT: {txt.name}\")\n",
    "    \n",
    "    # Load CSV files\n",
    "    csv_files = list(directory_path.glob(\"*.csv\"))\n",
    "    for csv in csv_files:\n",
    "        loader = CSVLoader(str(csv))\n",
    "        docs = loader.load()\n",
    "        all_docs.extend(docs)\n",
    "        print(f\"  ‚úÖ CSV: {csv.name} ({len(docs)} rows)\")\n",
    "    \n",
    "    # Load JSON files\n",
    "    json_files = list(directory_path.glob(\"*.json\"))\n",
    "    for json_file in json_files:\n",
    "        try:\n",
    "            loader = JSONLoader(\n",
    "                str(json_file),\n",
    "                jq_schema=\".\",\n",
    "                text_content=False\n",
    "            )\n",
    "            docs = loader.load()\n",
    "            all_docs.extend(docs)\n",
    "            print(f\"  ‚úÖ JSON: {json_file.name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è JSON: {json_file.name} (error: {str(e)[:50]}...)\")\n",
    "    \n",
    "    print(f\"\\nüìä Total: {len(all_docs)} documents loaded\")\n",
    "    return all_docs\n",
    "\n",
    "# Test the function\n",
    "if Path(\"sample_data\").exists():\n",
    "    all_documents = load_all_documents(\"sample_data\")\n",
    "    \n",
    "    # Show summary\n",
    "    print(f\"\\nüìà Summary:\")\n",
    "    sources = [doc.metadata['source'] for doc in all_documents]\n",
    "    print(f\"   Files loaded: {len(set(sources))}\")\n",
    "    print(f\"   Total documents: {len(all_documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"comparison\"></a>\n",
    "## 9. Loader Comparison Table üìä\n",
    "\n",
    "### üî∞ BEGINNER REFERENCE\n",
    "\n",
    "| Loader | File Type | Use Case | Documents Created |\n",
    "|--------|-----------|----------|-------------------|\n",
    "| **PyPDFLoader** | `.pdf` | Research papers, books, reports | 1 per page |\n",
    "| **CSVLoader** | `.csv` | Product catalogs, data tables | 1 per row |\n",
    "| **JSONLoader** | `.json` | API responses, config files | Depends on jq query |\n",
    "| **WebBaseLoader** | Web URLs | Blog posts, documentation | 1 per URL |\n",
    "| **TextLoader** | `.txt` | Plain text, logs | 1 per file |\n",
    "| **UnstructuredMarkdownLoader** | `.md` | Documentation, notes | 1 per file |\n",
    "| **DirectoryLoader** | Multiple | Batch processing | All files matching pattern |\n",
    "\n",
    "### When to Use Which?\n",
    "\n",
    "- üìï **Academic papers?** ‚Üí PyPDFLoader\n",
    "- üìä **Structured data?** ‚Üí CSVLoader\n",
    "- üîß **API data?** ‚Üí JSONLoader\n",
    "- üåê **Web content?** ‚Üí WebBaseLoader\n",
    "- üìù **Simple text?** ‚Üí TextLoader\n",
    "- üìÇ **Entire folder?** ‚Üí DirectoryLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"best-practices\"></a>\n",
    "## 10. Best Practices üåü\n",
    "\n",
    "### üî∞ BEGINNER TIPS\n",
    "\n",
    "#### 1. Always Check File Existence\n",
    "```python\n",
    "# ‚úÖ Good\n",
    "if Path(file_path).exists():\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    docs = loader.load()\n",
    "else:\n",
    "    print(f\"File not found: {file_path}\")\n",
    "\n",
    "# ‚ùå Bad - Will crash if file doesn't exist\n",
    "loader = PyPDFLoader(file_path)\n",
    "docs = loader.load()\n",
    "```\n",
    "\n",
    "#### 2. Use Lazy Loading for Large Files\n",
    "```python\n",
    "# For PDFs > 100 pages or files > 10MB\n",
    "for page in loader.lazy_load():\n",
    "    process_page(page)\n",
    "```\n",
    "\n",
    "#### 3. Inspect Metadata\n",
    "```python\n",
    "# Always check what metadata is available\n",
    "print(docs[0].metadata)\n",
    "```\n",
    "\n",
    "### üéì INTERMEDIATE TIPS\n",
    "\n",
    "#### 1. Error Handling\n",
    "```python\n",
    "try:\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    docs = loader.load()\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {pdf_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading {pdf_path}: {e}\")\n",
    "```\n",
    "\n",
    "#### 2. Add Custom Metadata\n",
    "```python\n",
    "# Add custom metadata after loading\n",
    "for doc in documents:\n",
    "    doc.metadata['loaded_at'] = datetime.now().isoformat()\n",
    "    doc.metadata['category'] = 'research_paper'\n",
    "```\n",
    "\n",
    "#### 3. Filter Documents\n",
    "```python\n",
    "# Filter by metadata\n",
    "research_docs = [\n",
    "    doc for doc in all_documents \n",
    "    if 'research' in doc.metadata['source'].lower()\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"summary\"></a>\n",
    "## 11. Summary & Exercises üìù\n",
    "\n",
    "### üéâ What You Learned\n",
    "\n",
    "‚úÖ **Document Loaders** convert files into standardized Document objects\n",
    "\n",
    "‚úÖ **PyPDFLoader** loads PDF files (1 document per page)\n",
    "\n",
    "‚úÖ **CSVLoader** loads CSV data (1 document per row)\n",
    "\n",
    "‚úÖ **JSONLoader** uses jq syntax to extract data from JSON\n",
    "\n",
    "‚úÖ **WebBaseLoader** scrapes web pages (static HTML only)\n",
    "\n",
    "‚úÖ **TextLoader** handles plain text files\n",
    "\n",
    "‚úÖ **DirectoryLoader** batch processes multiple files\n",
    "\n",
    "‚úÖ All loaders return **Document** objects with `page_content` and `metadata`\n",
    "\n",
    "### üí° Practice Exercises\n",
    "\n",
    "#### üî∞ Beginner Exercises\n",
    "\n",
    "1. **Load a PDF and count pages**\n",
    "   - Use PyPDFLoader to load `attention.pdf`\n",
    "   - Print the number of pages\n",
    "   - Print the first 100 characters of page 1\n",
    "\n",
    "2. **Load CSV and find products by category**\n",
    "   - Load `products.csv`\n",
    "   - Filter documents to find only \"Electronics\"\n",
    "   - Print product names\n",
    "\n",
    "3. **Combine multiple files**\n",
    "   - Load notes.txt, products.csv, and api_response.json\n",
    "   - Count total documents\n",
    "   - Print unique sources\n",
    "\n",
    "#### üéì Intermediate Exercises\n",
    "\n",
    "1. **Build a multi-format loader**\n",
    "   - Create a function that accepts a directory path\n",
    "   - Automatically detect file types (.pdf, .csv, .json, .txt)\n",
    "   - Load all files and add custom metadata (file_type, loaded_date)\n",
    "\n",
    "2. **Extract specific data from JSON**\n",
    "   - Load `api_response.json`\n",
    "   - Use jq to extract only article titles\n",
    "   - Create a summary document with all titles\n",
    "\n",
    "3. **Lazy load and process**\n",
    "   - Use lazy_load() on a PDF\n",
    "   - Process each page and extract pages containing specific keywords\n",
    "   - Save filtered pages to a new list\n",
    "\n",
    "### üìö Next Steps\n",
    "\n",
    "In **Notebook 03: Text Splitting Strategies**, you'll learn how to:\n",
    "- Split long documents into chunks\n",
    "- Choose optimal chunk sizes\n",
    "- Handle overlap for better context\n",
    "- Use different splitters for different content types\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations! You now know how to load data from any source! üéâ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
